---
title: "Data transformation with dplyr"
subtitle: "Day 2 - Introduction to Data Analysis with R"
author: "Selina Baldauf"
institute: "Freie UniversitÃ¤t Berlin - Theoretical Ecology"
date: today
date-format: long
format: 
  revealjs:
    footer: "Selina Baldauf // Data transformation with dplyr"
    highlight-style: breeze
    mainfont: Cabinet Grotesk
    slide-number: true
    show-slide-number: all
    incremental: true
    self-contained: true
    code-line-numbers: true
    auto-stretch: false
    scrollable: false
    theme: slides.scss
    fig-align: center
execute: 
  echo: true
  warning: false
  message: false
  cache: true
knitr: 
  opts_chunk: 
    collapse: true
    comment: "#>"
from: markdown+emoji
---

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
options(dplyr.print_max = 5,
        pillar.print_max = 5)
```

## Data transformation

Data transformation is an important step in **understanding** the data and **preparing** it for further analysis.

![](img/day1/datascience_workflow_tidyverse.png)

<br>

We can use the tidyverse package `dplyr` for this.

## Data transformation

With `dplyr` we can (among other things)

:::{.nonincremental}

- **Filter** data to analyse only a part of it
- **Create** new variables
- **Summarize** data
- **Combine** multiple tables
- **Rename** variables
- **Reorder** observations or variables

:::

. . .
  
To get started load the package `dplyr`:

```{r eval=FALSE}
library(dplyr)
# or
library(tidyverse)
```

## Dplyr basic vocuabulary for data manipulation

- `filter()` picks observations (rows) based on their values
- `select()` picks variables (columns) based on their names
- `mutate()` adds new variables based on existing ones
- `summarize()` combines multiple values into a single summary value

[Perform any of these operations by group]{.fragment}

:::{.aside}

from [dplyr package description](https://dplyr.tidyverse.org/)

:::

## Dplyr basic vocabulary

All of the `dplyr` functions work similarly: <br> 

- **First argument** is the data (a tibble)
- **Other arguments** specify what to do exactly
- **Return** a tibble

## Example data

Soybean production for different use by year and country.

```{r}
soybean_use <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-06/soybean_use.csv')
soybean_use
```

:::{.aside}

Data from [Our World in Data](https://ourworldindata.org/forests-and-deforestation) provided by [tidytuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-04-06/readme.md)

:::

# `filter()` {.inverse}

> picks observations (rows) based on their value

![Artwork by [Allison Horst](https://twitter.com/allison_horst)](img/AllisonHorst/dplyr_filter.jpg){width=70%}

## Useful `filter()` helpers

These functions and operators help you filter your observations:

:::{.nonincremental}

- relational operators `<`, `>`, `==`, ...
- logical operators `&`, `|`, `!`
- `%in%` to filter multiple values
- `is.na()` to filter missing values
- `between()` to filter values that are between an upper and lower boundary
- `near()` to compare floating points (use instead of `==` for doubles)

:::

## `filter()`

Filter rows that contain the values for Germany

```{r}
filter(soybean_use, entity == "Germany")
```

. . .

`filter()` goes through each row of the data and return only those rows where the value for `entity` is `"Germany"` 

## `filter()` + `%in%`

Use the `%in%` operator to filter rows based on multiple values, e.g. countries

. . .

```{r}
countries_select <- c("Germany", "Austria", "Switzerland")
filter(soybean_use, entity %in% countries_select)
```

## `filter()` + `is.na()`

Filter only rows that don't have a country code (i.e. the continents etc.)

```{r}
filter(soybean_use, is.na(code))
```

. . .

Or the opposite: filter only the rows that have a country code with

```{r eval=FALSE}
filter(soybean_use, !is.na(code))
```

## `filter()` + `between()`

#### Combine different filters:

Select rows where

- the value for `years` is between 1970 and 1980
- the value for `entity` is Germany

:::{.fragment}

```{r}
filter(soybean_use, between(year, 1970, 1980) & entity == "Germany")
```

:::

# `select()` {.inverse}

> picks variables (columns) based on their names

## Useful `select()` helpers

:::{.nonincremental}

- `starts_with()` and `ends_with()`: variable names that start/end with a specific string
- `contains()`: variable names that contain a specific string
- `matches()`: variable names that  match a regular expression
- `any_of()` and `all_of()`: variables that are contained in a character vector

:::

## `select()`

Select the variables entity, year and human food

```{r}
select(soybean_use, entity, year, human_food)
```

. . .

Remove variables using `-`

```{r eval=FALSE}
select(soybean_use, -entity, -year, -human_food)
```

## `select()` + `ends_with()`

Select all columns that end with `"d"`

```{r eval=FALSE}
select(soybean_use, ends_with("d"))
```

```{r echo=FALSE}
print(select(soybean_use, ends_with("d")),n=3)
```

. . .

You can use the same structure for `starts_with()` and `contains()`.

```{r eval=FALSE}
# this does not match any rows in the soy bean data set
# but combinations like this are helpful for research data
select(soybean_use, starts_with("sample_"))

select(soybean_use, contains("_id_"))
```

## `select()` + `any_of()`/`all_of()`

Use a character vector in conjunction with column selection

```{r}
cols <- c("sample_", "year", "processed", "entity")
```

. . .

`any_of()` returns any columns that match an element in `cols`

```{r eval=FALSE}
select(soybean_use, any_of(cols))
```

```{r echo=FALSE}
print(select(soybean_use, any_of(cols)),n=1)
```

. . .

`all_of()` tries to match all elements in `cols` and returns an error if an element does not exist

```{r eval=FALSE}
select(soybean_use, all_of(cols))
```

```{r echo=FALSE,error=TRUE}
select(soybean_use, all_of(cols))
```

## `select()` + `from:to`

Multiple consecutive columns can be selected using the `from:to` structure with either column id or variable name:

```{r eval = FALSE}
select(soybean_use, 1:3)
select(soybean_use, code:animal_feed)
```

```{r echo=FALSE}
print(select(soybean_use, code:animal_feed), n=3)
```

. . .

Be a bit careful with these commands: They are not robust if you e.g. change the order of your columns at some point. <br>

# `mutate()` {.inverse}
> Adds new variables

![Artwork by [Allison Horst](https://twitter.com/allison_horst)](img/AllisonHorst/dplyr_mutate.png){width=45%}

## `mutate()`

New columns can be added based on values from other columns

```{r eval=FALSE}
mutate(soybean_use,
  sum_human_animal = human_food + animal_feed
)
```

```{r echo=FALSE}
print(mutate(soybean_use,sum_human_animal = human_food + animal_feed), n= 3)
```

. . .

Add multiple new columns at once:

```{r eval=FALSE}
mutate(soybean_use,
  sum_human_animal = human_food + animal_feed,
  total = human_food + animal_feed + processed
)
```

## `mutate()` + `case_when()`

Use `case_when` to add column values conditional on other columns.

`case_when()` can combine many cases into one.

```{r}
mutate(soybean_use,
  legislation = case_when(
    between(year, 1980, 2000) ~ "legislation_1",  # case 1
    year >= 2000 ~ "legislation_2",               # case 2
    .default = "no_legislation"                   # all other cases
  )
)
```

# `summarize()` {.inverse}

> summarizes data

## `summarize()`

`summarize` will **collapse the data to a single row**

. . .

```{r}
summarize(soybean_use,
  total_animal = sum(animal_feed, na.rm = TRUE),
  total_human = sum(human_food, na.rm = TRUE)
)
```

## `summarize()` by group

`summarize` is much more useful in combination with the grouping argument `.by`

- **summary** will be calculated **separately for each group**

. . .

```{r}
# summarize the grouped data
summarize(soybean_use,
  total_animal = sum(animal_feed, na.rm = TRUE),
  total_human = sum(human_food, na.rm = TRUE),
  .by = year
)
```

## `count()`

Counts observations by group

```{r}
# count rows grouped by year
count(soybean_use, year)
```

# The pipe ` |> ` {.inverse}

> Combine multiple data operations into one command

## The pipe `|>`

Data transformation often requires **multiple operations** in sequence.

The pipe operator `|>` helps to keep these operations clear and readable.

- You may also see `%>%` from the `magrittr` package
- Turn on the native R pipe ` |> ` in **Tools -> Global Options -> Code**

:::{.fragment}

![](img/day2/native-pipe.png){width=50%}

:::

:::{.aside}

See [here](https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/) for differences 
between the two pipe versions

:::

## The pipe `|>`

Let's look at an example without pipe:

```{r eval=FALSE}
# 1: filter rows that actually represent a country
soybean_new <- filter(soybean_use, !is.na(code))

# 2: summarize mean values by year
soybean_new <- summarize(soybean_new,
  mean_processed = mean(processed, na.rm = TRUE),
  sd_processed = sd(processed, na.rm = TRUE),
  .by = year
)
```

. . .

**How could we make this more efficient?**

## The pipe `|>` 

We could do everything in one step without intermediate results by using use one **nested function**

```{r eval=FALSE}
soybean_new <- summarize(
  filter(soybean_use, !is.na(code)),
  mean_processed = mean(processed, na.rm = TRUE),
  sd_processed = sd(processed, na.rm = TRUE),
  .by = year
)
```

. . .

But this gets complicated and error prone very quickly

## The pipe `|>`

The pipe operator makes it very easy to combine multiple operations:

```{r eval=FALSE}
soybean_new <- soybean_use |>
  filter(!is.na(code)) |>
  summarize(
    mean_processed = mean(processed, na.rm = TRUE),
    sd_processed = sd(processed, na.rm = TRUE),
    .by = year
  )
```

. . .

You can read from top to bottom and interpret the `|>` as an "and then do".

## The pipe `|>`

But what is happening?

The pipe is "pushing" the result of one line into the first argument of the function from the next line.

. . .

```{r eval=FALSE}
soybean_use |> 
  count(year)

# instead of 
count(soybean_use, year)
```

. . .

Piping works perfectly with the `tidyverse` functions because they are designed
to return a tibble **and** take a tibble as first argument.

. . .

:::{.callout-tip}
Use the keyboard shortcut ` Ctrl/Cmd + Shift + M ` to insert ` |> `
:::

## The pipe `|>`

Piping also works well together with `ggplot`

```{r}
#| output-location: column
soybean_use |>
  filter(!is.na(code)) |>
  select(year, processed) |>
  summarize(
    processed = sum(processed,
      na.rm = TRUE
    ),
    .by = year
  ) |>
  ggplot(aes(
    x = year,
    y = processed
  )) +
  geom_line()
```

# Combining mulitiple tables{.inverse}

## Combine two tibbles by row `bind_rows`

Situation: Two (or more) `tibbles` with the same variables (column names)

```{r}
tbl_a <- soybean_use[1:2, ] # first two rows
tbl_b <- soybean_use[2:nrow(soybean_use), ] # the rest
```
<br>
```{r eval=FALSE}
tbl_a
```

```{r echo=FALSE}
print(tbl_a, n = 2)
```
<br>
```{r eval=FALSE}
tbl_b
```

```{r echo=FALSE}
print(tbl_b, n = 2)
```

## Combine two tibbles by row `bind_rows`

Bind the rows together with `bind_rows()`:

```{r eval=FALSE}
bind_rows(tbl_a, tbl_b)
```

```{r echo=FALSE}
print(bind_rows(tbl_a, tbl_b), n = 2)
```

. . .

You can also add an ID-column to indicate which line belonged to which table:

```{r eval=FALSE}
bind_rows(a = tbl_a, b = tbl_b, .id = "id")
```

```{r echo=FALSE}
print(bind_rows(a = tbl_a, b = tbl_b, .id = "id"), n = 3)
```

. . .

You can use `bind_rows()` to bind as many tables as you want:

```{r eval=FALSE}
bind_rows(a = tbl_a, b= tbl_b, c = tbl_c, ..., .id = "id")
```

## Join tibbles with `left_join()`

Situation: Two tables that share some but not all columns.

. . .

```{r echo=FALSE}
gdp <- select(soybean_use, entity,year) |> mutate(gdp = rnorm(1, mean = 5, sd = 0.5))
```

```{r eval = FALSE}
soybean_use
```

```{r echo = FALSE}
print(soybean_use, n=2)
```
<br>
```{r eval=FALSE}
# table with the gdp of the country/continent for each year
gdp
```

```{r echo = FALSE}
print(gdp, n=2)
```

## Join tibbles with `left_join()`

Join the two tables by the two common columns `entity` and `year`

```{r}
left_join(soybean_use, gdp, by = c("entity", "year"))
```

. . .

`left_join()` means that the resulting tibble will contain all rows of `soybean_use`,
but not necessarily all rows of `gdp`

## Different `*_join()` functions

![](img/day2/dplyr_join.png){width=70% fig-align="center"}

# Summary{.inverse}

> Data transformation with dplyr

## Summary I

All `dplyr` functions take a tibble as first argument and return a tibble.

#### `filter()`

:::{.nonincremental}

- **pick rows** with helpers
  - relational and logical operators
  - `%in%`
  - `is.na()`
  - `between()`
  - `near()`
  
:::

## Summary II

:::{.nonincremental}

All `dplyr` functions take a tibble as first argument and return a tibble.
  
#### `select()`

- **pick columns** with helpers
  - `starts_with()`, `ends_with()`
  - `contains()`
  - `matches()`
  - `any_of()`, `all_of()`
  
:::
  
## Summary III

#### `arrange()`

:::{.nonincremental}

- **change order** of rows (adscending)
  - or descending with `desc()`

#### `mutate()`

- **add columns** but keep all columns
  - `case_when()` for conditional values
  
:::

## Summary IV

:::{.nonincremental}

#### `summarize()`

- **collapse rows** into one row by some summary
  - use `.by` argument to summarize by group

#### `count`

- **count rows** based on a group

:::
  
## Summary V

:::{.nonincremental}

#### `bind_rows()`

- **combine rows** of multiple tibbles into one
  - the tibbles need to have the same columns
  - add an id column with the argument `.id = "id"`
  - function `bind_cols()` works similarly just for columns
  
#### `left_join()`

- **combine tables** based on common columns

:::

# Now you {.inverse}

[Task (60 min)]{.highlight-blue}<br>

[Transform the penguin data set]{.big-text}

**Find the task description [here](https://selinazitrone.github.io/intro-r-data-analysis/sessions/08_dplyr.html)**
