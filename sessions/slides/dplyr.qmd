---
title: "Data transformation with dplyr"
subtitle: "Day 2 - Introduction to Data Analysis with R"
author: "Selina Baldauf"
institute: "Freie UniversitÃ¤t Berlin - Theoretical Ecology"
date: today
date-format: long
format: 
  revealjs:
    footer: "Selina Baldauf // Data transformation with dplyr"
    highlight-style: breeze
    mainfont: Cabinet Grotesk
    slide-number: true
    show-slide-number: all
    incremental: true
    self-contained: true
    code-line-numbers: false
    auto-stretch: false
    scrollable: false
    theme: slides.scss
    fig-align: center
execute: 
  echo: true
  warning: false
  message: false
  cache: true
knitr: 
  opts_chunk: 
    collapse: true
    comment: "#>"
from: markdown+emoji
---

```{r setup, include=FALSE, cache = TRUE}
library(dplyr)
library(ggplot2)
options(dplyr.print_max = 5,
        pillar.print_max = 5)
```

## Data transformation

Data transformation is an important step in **understanding** the data and **preparing** it for further analysis.

![](img/day1/datascience_workflow_tidyverse.png)

<br>

We can use the tidyverse package `dplyr` for this.

## Data transformation

With `dplyr` we can (among other things)

:::{.nonincremental}

- **Filter** data to analyse only a part of it
- **Create** new variables
- **Summarize** data
- **Combine** multiple tables
- **Rename** variables
- **Reorder** observations or variables

:::

. . .
  
To get started load the package `dplyr`:

```{r eval=FALSE}
library(dplyr)
# or
library(tidyverse)
```

## Dplyr basic vocabulary

All of the `dplyr` functions work similarly: <br> 

- **First argument** is the data (a tibble)
- **Other arguments** specify what to do exactly
- **Return** a tibble

## The data

Data set `and_vertebrates` with measurements of a trout and 2 salamander species in different forest sections.

:::{.columns}

:::{.column width="60%"}

::: {.nonincremental}

::: {.small}

- `year`: observation year
- `section`: CC (clear cut forest) or OG (old growth forest)
- `unittype`: channel classification (C = Cascade, P = Pool, ...)
- `species`: Species measured
- `length_1_mm`: body length [mm]
- `weight_g`: body weight [g]

:::

:::

:::{.aside}
References: [Kaylor, M.J. and D.R. Warren. (2017)](https://doi.org/10.1002/ecs2.1845) and<br>[Gregory, S.V. and I. Arismendi. (2020)](https://doi.org/10.6073/pasta/7c78d662e847cdbe33584add8f809165) as provided in the <br>[lterdatasampler package](https://lter.github.io/lterdatasampler/).

:::

:::

:::{.column width="40%"}

![Coastal giant salamander (terrestrial form)<br>Andrews Forest Program by Lina DiGregorio via CC-BY from [https://andrewsforest.oregonstate.edu](https://andrewsforest.oregonstate.edu)](https://andrewsforest.oregonstate.edu/sites/default/files/gallery/afb_037.jpg){width=60%}

:::

:::

## The data

Data set `and_vertebrates` with measurements of a trout and 2 salamander species in different forest sections.

```{r}
library(lterdatasampler)
vertebrates <- and_vertebrates |>
  select(year, section, unittype, species, length_1_mm, weight_g) |>
  filter(species != "Cascade torrent salamander")
vertebrates
```

# `filter()` {.inverse}

> picks rows based on their value



## `filter()`

Filter only the trout species:

```{r}
filter(vertebrates, species == "Cutthroat trout")
```

. . .

`filter()` goes through each row of the data and return only those rows where the value for `species` is `"Cutthroat trout"`

## `filter()`

You can also combine filters using logical operators (`&`, `|`, `!`):

```{r}
filter(vertebrates, species == "Cutthroat trout" & year == 1987)
```

## `filter()` + `%in%`

Use the `%in%` operator to filter rows based on multiple values, e.g. unittypes

. . .

```{r}
unittype_select <- c("R", "C", "S")
filter(vertebrates, unittype %in% unittype_select)
```

## `filter()` + `is.na()`

Filter only rows that don't have a value for the weight

```{r}
filter(vertebrates, is.na(weight_g))
```

. . .

Or the opposite: filter only the rows that have a value for the weight

```{r eval=FALSE}
filter(vertebrates, !is.na(weight_g))
```

## `filter()` + `between()`

#### Combine different filters:

Filter rows where the value for `year` is between 2000 and 2005

:::{.fragment}

```{r}
filter(vertebrates, between(year, 2000, 2005))
```

:::

:::{.fragment}

Or you could also do it like this: 

```{r eval=FALSE}
filter(vertebrates, year >= 2000 & year <= 2005)
```

:::

## Useful `filter()` helpers

These functions and operators help you filter your observations:

:::{.nonincremental}

- relational operators `<`, `>`, `==`, ...
- logical operators `&`, `|`, `!`
- `%in%` to filter multiple values
- `is.na()` to filter missing values
- `between()` to filter values that are between an upper and lower boundary
- `near()` to compare floating points (use instead of `==` for doubles)

:::

# `select()` {.inverse}

> picks columns based on their names

## `select()`

Select the columns `species`, `length_1_mm`, and `year`

```{r}
select(vertebrates, species, length_1_mm, year)
```

. . .

Remove variables using `-`

```{r eval=FALSE}
select(vertebrates, -species, -length_1_mm, -year)
```

## `select()` + `starts_with()`

Select all columns that start with `"s"`

```{r eval=FALSE}
select(vertebrates, starts_with("s"))
```

```{r echo=FALSE}
print(select(vertebrates, starts_with("s")),n=3)
```

. . .

You can use the same structure for `ends_with()` and `contains()`.

```{r eval=FALSE}
# this does not make sense for the example data
# but combinations like this are helpful for research data
select(vertebrates, starts_with("_location1"))

select(vertebrates, contains("_id_"))
```

## `select()` + `from:to` {visibility="hidden"}

Multiple consecutive columns can be selected using the `from:to` structure with either column id or name:

```{r eval = FALSE}
select(vertebrates, 1:3)
select(vertebrates, year:unittype)
```

```{r echo=FALSE}
print(select(vertebrates, year:unittype), n=3)
```

. . .

Be a bit careful with these commands: They are not robust if you e.g. change the order of your columns at some point. <br>

## Useful `select()` helpers

:::{.nonincremental}

- `starts_with()` and `ends_with()`: variable names that start/end with a specific string
- `contains()`: variable names that contain a specific string
- `matches()`: variable names that  match a regular expression
- `any_of()` and `all_of()`: variables that are contained in a character vector

:::

# `mutate()` {.inverse}

> Adds new columns to your data

## `mutate()`

New columns can be added based on values from other columns

```{r eval=FALSE}
mutate(vertebrates, weight_kg = weight_g/1000)
```

```{r echo=FALSE}
print(mutate(vertebrates, weight_kg = weight_g/1000), n= 3)
```

. . .

Add multiple new columns at once:

```{r eval=FALSE}
mutate(vertebrates,
       weight_kg = weight_g/1000,
       length_m = length_1_mm/1000)

```

## `mutate()` + `case_when()`

Use `case_when` to add column values conditional on other columns.

`case_when()` can combine many cases into one.

```{r}
mutate(vertebrates,
       type = case_when(
         species == "Cutthroat trout" ~ "Fish",               # case 1
         species == "Coastal giant salamander" ~ "Amphibian", # case 2
         .default = NA                                        # all other
))
```

# `summarize()` {.inverse}

> summarizes data

## `summarize()`

`summarize` will **collapse the data to a single row**

. . .

```{r}
summarize(vertebrates,
          mean_length = mean(length_1_mm, na.rm = TRUE),
          mean_weight = mean(weight_g, na.rm = TRUE))
```

## `summarize()` by group

`summarize` is much more useful in combination with the grouping argument `.by`

- **summary** will be calculated **separately for each group**

. . .

```{r}
# summarize the grouped data
summarize(vertebrates,
    mean_length = mean(length_1_mm, na.rm = TRUE),
    mean_weight = mean(weight_g, na.rm = TRUE),
    .by = species
  )
```

. . .

- Combine variables if you want to summarize by more than one group (e.g. `.by = c(species, unittype)`)

## `count()`

Counts observations by group

```{r}
# count rows grouped by year
count(vertebrates, year)
```

# The pipe ` |> ` {.inverse}

> Combine multiple data operations into one command

## The pipe `|>`

Data transformation often requires **multiple operations** in sequence.

The pipe operator `|>` helps to keep these operations clear and readable.

- You may also see `%>%` from the `magrittr` package

:::{.fragment}

Turn on the native R pipe ` |> ` in **Tools -> Global Options -> Code**


![](img/day2/native-pipe.png){width=50%}

:::

:::{.aside}

See [here](https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/) for differences 
between the two pipe versions

:::

## The pipe `|>`

Let's look at an example without pipe:

```{r eval=FALSE}
# 1: filter rows that have don't have NA in the unittype column
vertebrates_new <- filter(vertebrates, !is.na(unittype))

# 2: summarize mean values by year
vertebrates_new <- count(vertebrates_new, year, species, section)
```

. . .

**How could we make this more efficient?**

. . .

Use one **nested function** without intermediate results:

```{r eval=FALSE}
vertebrates_new <- count(
  filter(vertebrates, !is.na(unittype)),
  year, species, section
)
```

. . .

But this gets complicated and error prone very quickly

## The pipe `|>`

The pipe operator makes it very easy to combine multiple operations:

```{r eval=FALSE}
vertebrates_new <- vertebrates |>
  filter(!is.na(unittype)) |>
  count(year, species, section)

vertebrates_new
```

. . .

You can read from top to bottom and interpret the `|>` as an "and then do".

## The pipe `|>`

But what is happening?

The pipe is "pushing" the result of one line into the first argument of the function from the next line.

. . .

```{r eval=FALSE}
vertebrates |> 
  count(year)

# instead of 
count(vertebrates, year)
```

. . .

Piping works perfectly with the `tidyverse` functions because they are designed
to return a tibble **and** take a tibble as first argument.

. . .

:::{.callout-tip}
Use the keyboard shortcut ` Ctrl/Cmd + Shift + M ` to insert ` |> `
:::

## The pipe `|>`

Piping also works well together with `ggplot`

```{r}
#| echo: false
theme_set(theme_bw(base_size = 16))
```


```{r fig.height=4}
vertebrates |>
  filter(!is.na(unittype)) |>
  count(year, species, section) |>
  ggplot(aes(x = year, y = n, color = species)) +
  geom_line() +
  facet_wrap(~section)
```

# Combining mulitiple tables{.inverse}

## Combine two tibbles by row `bind_rows`

Situation: Two (or more) `tibbles` with the same variables (column names)

```{r}
tbl_a <- vertebrates[1:2, ] # first two rows
tbl_b <- vertebrates[2:nrow(vertebrates), ] # the rest
```
<br>
```{r eval=FALSE}
tbl_a
```

```{r echo=FALSE}
print(tbl_a, n = 2)
```
<br>
```{r eval=FALSE}
tbl_b
```

```{r echo=FALSE}
print(tbl_b, n = 2)
```

## Combine two tibbles by row `bind_rows`

Bind the rows together with `bind_rows()`:

```{r eval=FALSE}
bind_rows(tbl_a, tbl_b)
```

```{r echo=FALSE}
print(bind_rows(tbl_a, tbl_b), n = 2)
```

. . .

You can also add an ID-column to indicate which line belonged to which table:

```{r eval=FALSE}
bind_rows(a = tbl_a, b = tbl_b, .id = "id")
```

```{r echo=FALSE}
print(bind_rows(a = tbl_a, b = tbl_b, .id = "id"), n = 3)
```

. . .

You can use `bind_rows()` to bind as many tables as you want:

```{r eval=FALSE}
bind_rows(a = tbl_a, b= tbl_b, c = tbl_c, ..., .id = "id")
```

## Join tibbles with `left_join()`

Situation: Two tables that share some but not all columns.

. . .

```{r echo=FALSE}
species <- select(vertebrates, species) |> distinct() |> 
  mutate(type = case_when(
    species == "Cutthroat trout" ~ "Fish",
    species == "Coastal giant salamander" ~ "Amphibian"
  ))
```

```{r eval = FALSE}
vertebrates
```

```{r echo = FALSE}
print(vertebrates, n=2)
```
<br>
```{r}
# table with more information on the species
species
```

## Join tibbles with `left_join()`

Join the two tables by the common column `species`

```{r}
left_join(vertebrates, species, by = "species")
```

. . .

`left_join()` means that the resulting tibble will contain all rows of `vertebrates`,
but not necessarily all rows of `species` (in this case it does though).

## Different `*_join()` functions

![](img/day2/dplyr_join.png){width=70% fig-align="center"}

# Summary{.inverse}

> Data transformation with dplyr

## Summary I

All `dplyr` functions take a tibble as first argument and return a tibble.

#### `filter()`

:::{.nonincremental}

- **pick rows** with helpers
  - relational and logical operators
  - `%in%`
  - `is.na()`
  - `between()`
  - `near()`
  
:::

## Summary II

:::{.nonincremental}

All `dplyr` functions take a tibble as first argument and return a tibble.
  
#### `select()`

- **pick columns** with helpers
  - `starts_with()`, `ends_with()`
  - `contains()`
  - `matches()`
  - `any_of()`, `all_of()`
  
:::
  
## Summary III

#### `arrange()`

:::{.nonincremental}

- **change order** of rows (adscending)
  - or descending with `desc()`

#### `mutate()`

- **add columns** but keep all columns
  - `case_when()` for conditional values
  
:::

## Summary IV

:::{.nonincremental}

#### `summarize()`

- **collapse rows** into one row by some summary
  - use `.by` argument to summarize by group

#### `count`

- **count rows** based on a group

:::
  
## Summary V

:::{.nonincremental}

#### `bind_rows()`

- **combine rows** of multiple tibbles into one
  - the tibbles need to have the same columns
  - add an id column with the argument `.id = "id"`
  - function `bind_cols()` works similarly just for columns
  
#### `left_join()`

- **combine tables** based on common columns

:::

# Now you {.inverse}

[Task (30 min)]{.highlight-blue}<br>

[Transform the penguin data set]{.big-text}

**Find the task description [here](https://selinazitrone.github.io/intro-r-data-analysis/sessions/08_dplyr.html)**
