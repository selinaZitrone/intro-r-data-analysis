---
subtitle: "Introduction to R - Day "
author: "Selina Baldauf"
institute: "Freie Universit√§t Berlin - Theoretical Ecology"
date: "2021-06-15"
output:
  xaringan::moon_reader:
    seal: false
    css: [default, css/new_slides.css]
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: false
      beforeInit: "macros.js"
params:
  title: "Data transformation with dplyr"
  day: "2"
  bg_image: "img/hex-stickers/dplyr.png"
  bg_image_scale: "30%"
  bg_position: "90% 90%"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE, 
  message = FALSE, 
  collapse = TRUE,
  fig.height = 6.3,
  fig.allign = 'center',
  fig.retina = 3.5,
  fig.showtext = TRUE
)
library(fontawesome)
library(tidyverse)
```

```{r child="title_slide.Rmd"}

```

---
# Data transformation

Data transformation is an important step in understanding the data and preparing it for further analysis.

 .center[![](img/day2/datascience_workflow.png)]

---
# Data transformation

Data transformation is an important step in understanding the data and preparing it for further analysis.

We may want to:

  - **filter** the data to analyse only a part of it
  - **reorder** observations or variables 
  - **create** new variables
  - **summarize** the data
  - **rename** variables
  
--
  
We can do all of this with `dplyr`:

```{r eval=FALSE}
library(dplyr)
# or
library(tidyverse)
```

---
# Dplyr basic vocuabulary


#### `dplyr` provides basic vocabulary for data manipulation:

- `filter()` picks observations (rows) based on their values

--

- `select()` picks variables (columns) based on their names

--

- `arrange()` change order of observations (rows)

--

- `mutate()` adds new variables based on existing ones

--

- `summarise()` combines multiple values into a single summary value

Perform any of these operations by group with `group_by()`

.footnote-right[from [dplyr package description](https://dplyr.tidyverse.org/)]

---
# Dplyr basic vocabulary

All of the `dplyr` functions work similarly: <br> 

- **first argument** is the data (a tibble)

- **other arguments** specify what to do exactly

- **returns** a tibble

---
# Example data

Soybean production and use by year and country.

```{r eval=FALSE}
soybean_use <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-06/soybean_use.csv')
soybean_use
```

```{r echo=FALSE}
soybean_use <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-06/soybean_use.csv')
print(soybean_use, n=5)
```
.footnote-right[Data from [Our World in Data](https://ourworldindata.org/forests-and-deforestation) provided by [tidytuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-04-06/readme.md)]

---
class: inverse, center, middle

# `filter()`
## picks observations (rows) based on their value

.center[![:scale 77%](img/AllisonHorst/dplyr_filter.jpg)]

.footnote-right[Artwork by <br> [Allison Horst](https://twitter.com/allison_horst)]

---
# Useful `filter()` helpers

These functions and operators help you filter your observations:

--

- relational operators: `<`, `>`, `==`, ...

--

- logical operators: `&`, `|`, `!`

--

- `is.na()`: filter missing values

--

- `between()`: filter values that are between an upper and lower boundary

--

- `near()`: compare floating points (use instead of `==` for doubles)


---
# `filter()`

Filter rows that contain the values for Germany

```{r eval=FALSE}
filter(soybean_use, entity == "Germany")
```

```{r echo=FALSE}
print(filter(soybean_use, entity == "Germany"), n=5)
```

--

`filter()` will go through each row of the data and return only those rows for which the value for `entity` is `"Germany"` 

---
# `filter()`

We can use the `%in%` operator to filter multiple countries

```{r eval=FALSE}
countries_select <- c("Germany", "Austria", "Switzerland")
filter(soybean_use, entity %in% countries_select)
```

```{r echo=FALSE}
countries_select <- c("Germany", "Austria", "Switzerland")
print(filter(soybean_use, entity %in% countries_select), n=5)
```

---
# `filter()`

Let's filter only rows that don't have a country code (i.e. the continents etc.)

```{r eval=FALSE}
filter(soybean_use, is.na(code))
```

```{r echo=FALSE}
print(filter(soybean_use, is.na(code)), n=5)
```

--

Or the opposite: filter only the rows that have a country code with:

```{r eval=FALSE}
filter(soybean_use, !is.na(code))
```

---
# `filter()`

#### Combine different filters:

Select rows where

- the value for `years` is between 1970 and 1980
- the value for `entity` is Germany

```{r eval=FALSE}
filter(soybean_use, between(year, 1970, 1980) & entity == "Germany")
```

```{r echo=FALSE}
print(filter(soybean_use, between(year, 1970, 1980) & entity == "Germany"), n=5)
```

---
class:inverse, center, middle

# `select()`

## picks variables (columns) based on their names
---
# Useful `select()` helpers
<br>

- `starts_with()` and `ends_with()`: variable names that start/end with a string

--

- `contains()`: variable names that contain a specific string

--

- `matches()`: variable names match a regular expression

---
# `select()`

Select the variables entity, year and human food

```{r eval=FALSE}
select(soybean_use, entity, year, human_food)
```

```{r echo=FALSE}
print(select(soybean_use, entity, year, human_food), n=2)
```

--

Remove variables using `-`

```{r eval=FALSE}
select(soybean_use, -entity, -year, -human_food)
```


```{r echo=FALSE}
print(select(soybean_use, -entity, -year, -human_food),n=2)
```

---
# `select()`

Select all columns that end with `"d"`

```{r eval=FALSE}
select(soybean_use, ends_with("d"))
```

```{r echo=FALSE}
print(select(soybean_use, ends_with("d")),n=3)
```

--

You can use the same structure for `starts_with()` and `contains()`.

E.g.

```{r eval=FALSE}
# this does not match any rows in the soy bean data set
# but combinations like this are helpful for research data
select(soy_bean_use, starts_with("sample_"))

select(soy_bean_use, contains("_id_"))
```

---
# `select()`

Multiple consecutive columns can be selected using the `from:to` structure with either column id or variable name:

```{r eval = FALSE}
select(soybean_use, 1:3)
select(soybean_use, code:animal_feed)
```

```{r echo=FALSE}
print(select(soybean_use, code:animal_feed), n=3)
```

--

Be a bit careful with these commands: <br>

Make sure you really select the columns you want even if e.g. the order of the columns might change

---
class:inverse, center, middle

# `arrange()`
## change order of observations (rows)

---
# `arrange()`

Arrange the rows by **ascending** values of the processed variable:

```{r eval=FALSE}
arrange(soybean_use, processed)
```

```{r echo=FALSE}
print(arrange(soybean_use, processed), n=3)
```

--

Arrange the rows by **descending** values of the processed variable:

```{r eval=FALSE}
arrange(soybean_use, desc(processed))
```

--

Arranging also works for character columns. They will be sorted **alphabetically**.

---
class: inverse, center, middle

# `mutate()`
## adds new variables

![:scale 50%](img/AllisonHorst/dplyr_mutate.png)
.footnote-right[Artwork by [Allison Horst](https://twitter.com/allison_horst)]

---
# `mutate()`

We can add a new variable using `ifelse`:

```{r eval=FALSE}
mutate(soybean_use,
  single_country = ifelse(
    is.na(code),
    FALSE,
    TRUE
  )
)
```

```{r echo=FALSE}
print(mutate(soybean_use, single_country = ifelse(is.na(code), FALSE, TRUE)),n=3)
```

---
# `mutate()` and `case_when()`

Instead of `ifelse`, we can also use `case_when`

.center[![:scale 70%](img/AllisonHorst/dplyr_case_when.png)]

.footnote-right[Artwork by [Allison Horst](https://twitter.com/allison_horst)]

---
# `mutate()` and `case_when()`

`case_when()` can combine many cases into one. E.g.:

```{r eval=FALSE}
mutate(soybean_use,
  legislation = case_when(
    year < 2000 & year >= 1980 ~ "legislation_1",
    year >= 2000 ~ "legislation_2",
    TRUE ~ "no_legislation"
  )
)
```

```{r echo=FALSE}
mutate(soybean_use, legislation = case_when(
  year < 2000 & year >=1980 ~ "legislation_1",
  year >= 2000 ~ "legislation_2",
  TRUE ~ "no_legislation"
)) %>% print(n=3)
```

---
# `transmute()`

`transmute()` is like `mutate()` but only keeps the newly created columns:

```{r eval=FALSE}
transmute(soybean_use,
          ratio_processed_animal = processed/animal_feed,
          ratio_human_animal = human_food/animal_feed)

```

```{r echo=FALSE}
transmute(soybean_use,
          ratio_processed_animal = processed/animal_feed,
          ratio_human_animal = human_food/animal_feed) %>% 
  print(n=3)
```

---
class: inverse, center, middle

# `summarize()` + `group_by()`
## summarizes the data by group

---
# `summarize()`

`summarize` will **collapse the data to a single row**

```{r}
summarize(soybean_use,
          total_animal = sum(animal_feed, na.rm = TRUE),
          total_human = sum(human_food, na.rm = TRUE))
```

---
# `summarise()` and `group_by()`

`summarise` is much more useful in combination with `group_by()`.

If you group the data before summarizing it, the **summary** will be calculated **separately for each group**

```{r eval=FALSE}
# group the data by year
soybean_use_group <- group_by(soybean_use, year)
# summarize the grouped data
summarize(soybean_use_group,
          total_animal = sum(animal_feed, na.rm = TRUE),
          total_human = sum(human_food, na.rm = TRUE))
```

```{r echo=FALSE}
# group the data by year
soybean_use_group <- group_by(soybean_use, year)

summarise(soybean_use_group,
          total_animal = sum(animal_feed, na.rm = TRUE),
          total_human = sum(human_food, na.rm = TRUE)) %>% print(n=2)
```

--

To ungroup data that was grouped before, you can use `ungroup()`

---
# `count()`

Counts observations by group

```{r eval = FALSE}
# count rows grouped by year
count(soybean_use, year)

# or if the data is already grouped by year
count(soybean_use_group)
```

```{r echo = FALSE}
count(soybean_use_group) %>% print(n=4)
```

---
class: inverse, middle, center

# The pipe `%>%`

---
# The pipe `%>%`

Data transformation often requires **multiple operations** in sequence.

The pipe operator `%>%` helps to keep these operations clear and readable.

---
# The pipe `%>%`

Let's look at an example without pipe:

```{r eval=FALSE}
# 1: filter rows that actually represent a country
soybean_new <- filter(soybean_use, !is.na(code))

# 2: group the data by year
soybean_new <- group_by(soybean_new, year)

# 3: summarize mean values by year
soybean_new <- summarize(soybean_new,
    mean_processed = mean(processed, na.rm=TRUE),
    sd_processed = sd(processed, na.rm = TRUE))

# 4: reorder the observation with newest first
soybean_new <- arrange(soybean_new, desc(year))
```

--

**How could we make this more efficient?**

---
# The pipe `%>%` 

We could do everything in one step without intermediate results by using use one **nested function**:

```{r eval=FALSE}
arrange(
  summarise(
    group_by(
      filter(soybean_use, !is.na(code)),
      year),
    mean_processed = mean(processed, na.rm=TRUE),
    sd_processed = sd(processed, na.rm = TRUE)),
  desc(year))
```


```{r echo=FALSE}
arrange(
  summarise(
    group_by(
      filter(soybean_use, !is.na(code)),
      year),
    mean_processed = mean(processed, na.rm=TRUE),
    sd_processed = sd(processed, na.rm = TRUE)),
  desc(year)) %>% print(n=4)
```

--

**But this gets complicated and error prone very quickly**

---
# The pipe `%>%`

The pipe operator (included in the `tidyverse`) makes it very easy to combine multiple operations:

```{r}
soybean_use %>%
  filter(!is.na(code)) %>%
  group_by(year) %>%
  summarise(
    mean_processed = mean(processed, na.rm = TRUE),
    sd_processed = sd(processed, na.rm = TRUE)
  ) %>%
  arrange(desc(year))
```

--

You can read from top to bottom and interpret the `%>%` as an "and then do".

---
# The pipe `%>%`

But what is happening?

The pipe is "pushing" the result of one line into the first argument of the function from the next line.

```{r eval=FALSE}
soybean_use %>% 
  count(year)

# instead of 
count(soybean_use, year)
```

--

Piping works perfectly with the `tidyverse` functions because they are designed to return a tibble **and** take a tibble as first argument. <br>

--

.content-box-yellow[`r fa("lightbulb")` Use the keyboard shortcut `Ctrl/Cmd + Shift + M` to insert a ` %>% ` pipe]

---
# The pipe `%>%`

Piping also works well together with `ggplot`

.pull-left[

```{r eval=FALSE}
soybean_use %>%
  filter(!is.na(code)) %>%
  select(year, processed) %>%
  group_by(year) %>%
  summarise(
    processed = sum(processed, na.rm = TRUE)
  ) %>%
  ggplot(aes(
    x = year,
    y = processed
  )) +
    geom_line()
```
]
.pull-right[

```{r echo=FALSE, fig.width=6.3}
soybean_use %>% 
  filter(!is.na(code)) %>% 
  select(year, processed) %>% 
  group_by(year) %>% 
  summarise(
    processed = sum(processed, na.rm = TRUE)
  ) %>% 
  ggplot(aes(x=year, y=processed))+
   geom_line()+
  theme_gray(base_size=16)
  
```
]
---
